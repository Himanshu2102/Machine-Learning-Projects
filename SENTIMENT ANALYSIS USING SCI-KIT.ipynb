{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af6a250",
   "metadata": {},
   "source": [
    " ### STEPS TO BE TAKEN : \n",
    "    Introduction and Importing the Data\n",
    "\n",
    "    Transforming Documents into Feature Vectors\n",
    "\n",
    "    Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "    Calculate the TF-IDF of the Term 'Is'\n",
    "\n",
    "    Data Preparation \n",
    "\n",
    "    Tokenization of Documents\n",
    "\n",
    "    Document Classification Using Logistic Regression\n",
    "\n",
    "    Load Saved Model from Disk\n",
    "\n",
    "    Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8169bc",
   "metadata": {},
   "source": [
    "#### Importing libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06707ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70acb49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\himanshu pandey\\Downloads\\movie_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0445f663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0\n",
       "3  hi for all the people who have seen this wonde...          1\n",
       "4  I recently bought the DVD, forgetting just how...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1b84b",
   "metadata": {},
   "source": [
    "#### The movie having atleast 7 stars can be labeled as positive\n",
    "#### The movie with atmost 4 stars can be labeled as negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "385e704c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiment\n",
       "count  50000.000000\n",
       "mean       0.500000\n",
       "std        0.500005\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.500000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2cbebfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8ed127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa009de",
   "metadata": {},
   "source": [
    "Total number of values = 50000, Total null values = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a2a441",
   "metadata": {},
   "source": [
    "##### Reading a complete review : for example 6th review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35489f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Leave it to Braik to put on a good show. Finally he and Zorak are living their own lives outside of Spac Ghost Coast To Coast. I have to say that I love both of these shows a whole lot. They are completely what started Adult Swim. Brak made it big with an album that came out in the year 2000. It may not have been platinum, but his show was really popular to tons of people out there that love Adult Swims shows. I have to say that out of all the Adult Swim shows with no plot, this has to be the one with the most none plot ever made. That is why I like it so much, it is just such a classic in the Adult Swim history. I believe this is just such a great show, if you don't like it. Hey there were tons who hated it and tons who loved it.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304785a4",
   "metadata": {},
   "source": [
    "#### Transforming documents into feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cef361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer()\n",
    "\n",
    "docs=np.array(['The sun is shining',\n",
    "              'The weather is sweet',\n",
    "              ' The sun is shining,The weather is sweet, and one and one is two'])\n",
    "\n",
    "\n",
    "bag=count.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a32c84f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 6, 'sun': 4, 'is': 1, 'shining': 3, 'weather': 8, 'sweet': 5, 'and': 0, 'one': 2, 'two': 7}\n"
     ]
    }
   ],
   "source": [
    "print(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d8eb33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 0 1 0 0]\n",
      " [0 1 0 0 0 1 1 0 1]\n",
      " [2 3 2 1 1 1 2 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bag.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7da7340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.43 0.   0.56 0.56 0.   0.43 0.   0.  ]\n",
      " [0.   0.43 0.   0.   0.   0.56 0.43 0.   0.56]\n",
      " [0.5  0.45 0.5  0.19 0.19 0.19 0.3  0.25 0.19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "np.set_printoptions(precision=2)\n",
    "tfidf = TfidfTransformer(use_idf = True, norm = 'l2',smooth_idf = True)\n",
    "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd95da1d",
   "metadata": {},
   "source": [
    "tfidf weights everything appropriately, from 3--> 0.45 weight is given to is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07043700",
   "metadata": {},
   "source": [
    "##### DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdbb5674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"Murder in Greenwich\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92cbee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=df.loc[0,'review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa17d5",
   "metadata": {},
   "source": [
    "###### A lot of data seems irrelevant in the review, it must be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "788d0ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub ('<[^>]*>','',text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text)\n",
    "    text=re.sub('[\\W]+',' ',text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "019919bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in 1974 the teenager martha moxley maggie grace moves to the high class area of belle haven greenwich connecticut on the mischief night eve of halloween she was murdered in the backyard of her house and her murder remained unsolved twenty two years later the writer mark fuhrman christopher meloni who is a former la detective that has fallen in disgrace for perjury in o j simpson trial and moved to idaho decides to investigate the case with his partner stephen weeks andrew mitchell with the purpose of writing a book the locals squirm and do not welcome them but with the support of the retired detective steve carroll robert forster that was in charge of the investigation in the 70 s they discover the criminal and a net of power and money to cover the murder murder in greenwich is a good tv movie with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a kennedy the powerful and rich family used their influence to cover the murder for more than twenty years however a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed the screenplay shows the investigation of mark and the last days of martha in parallel but there is a lack of the emotion in the dramatization my vote is seven title brazil not available'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a4f4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e501e896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in 1974 the teenager martha moxley maggie grac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok so i really like kris kristofferson and his...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spoiler do not read this if you think about w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i recently bought the dvd forgetting just how ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  in 1974 the teenager martha moxley maggie grac...          1\n",
       "1  ok so i really like kris kristofferson and his...          0\n",
       "2   spoiler do not read this if you think about w...          0\n",
       "3  hi for all the people who have seen this wonde...          1\n",
       "4  i recently bought the dvd forgetting just how ...          0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b88d87c",
   "metadata": {},
   "source": [
    "###### Tokenization of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c477cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "75577fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "762b7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd67e3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'recently',\n",
       " 'bought',\n",
       " 'the',\n",
       " 'dvd',\n",
       " 'forgetting',\n",
       " 'just',\n",
       " 'how',\n",
       " 'much',\n",
       " 'i',\n",
       " 'hated',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'version',\n",
       " 'of',\n",
       " 'a',\n",
       " 'chorus',\n",
       " 'line',\n",
       " 'every',\n",
       " 'change',\n",
       " 'the',\n",
       " 'director',\n",
       " 'attenborough',\n",
       " 'made',\n",
       " 'to',\n",
       " 'the',\n",
       " 'story',\n",
       " 'failed',\n",
       " 'by',\n",
       " 'making',\n",
       " 'the',\n",
       " 'director',\n",
       " 'cassie',\n",
       " 'relationship',\n",
       " 'so',\n",
       " 'prominent',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'ensemble',\n",
       " 'premise',\n",
       " 'of',\n",
       " 'the',\n",
       " 'musical',\n",
       " 'sails',\n",
       " 'out',\n",
       " 'the',\n",
       " 'window',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'musical',\n",
       " 'numbers',\n",
       " 'are',\n",
       " 'sped',\n",
       " 'up',\n",
       " 'and',\n",
       " 'rushed',\n",
       " 'the',\n",
       " 'show',\n",
       " 's',\n",
       " 'hit',\n",
       " 'song',\n",
       " 'gets',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'meaning',\n",
       " 'shattered',\n",
       " 'when',\n",
       " 'it',\n",
       " 'is',\n",
       " 'given',\n",
       " 'to',\n",
       " 'cassie',\n",
       " 's',\n",
       " 'character',\n",
       " 'the',\n",
       " 'overall',\n",
       " 'staging',\n",
       " 'is',\n",
       " 'very',\n",
       " 'self',\n",
       " 'conscious',\n",
       " 'the',\n",
       " 'only',\n",
       " 'reason',\n",
       " 'i',\n",
       " 'give',\n",
       " 'it',\n",
       " 'a',\n",
       " '2',\n",
       " 'is',\n",
       " 'because',\n",
       " 'a',\n",
       " 'few',\n",
       " 'of',\n",
       " 'the',\n",
       " 'great',\n",
       " 'numbers',\n",
       " 'are',\n",
       " 'still',\n",
       " 'able',\n",
       " 'to',\n",
       " 'be',\n",
       " 'enjoyed',\n",
       " 'despite',\n",
       " 'the',\n",
       " 'film',\n",
       " 's',\n",
       " 'attempt',\n",
       " 'to',\n",
       " 'squeeze',\n",
       " 'every',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'joy',\n",
       " 'and',\n",
       " 'spontaneity',\n",
       " 'out',\n",
       " 'of',\n",
       " 'it']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(df.loc[4,'review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c1a5ecb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'recent',\n",
       " 'bought',\n",
       " 'the',\n",
       " 'dvd',\n",
       " 'forget',\n",
       " 'just',\n",
       " 'how',\n",
       " 'much',\n",
       " 'i',\n",
       " 'hate',\n",
       " 'the',\n",
       " 'movi',\n",
       " 'version',\n",
       " 'of',\n",
       " 'a',\n",
       " 'choru',\n",
       " 'line',\n",
       " 'everi',\n",
       " 'chang',\n",
       " 'the',\n",
       " 'director',\n",
       " 'attenborough',\n",
       " 'made',\n",
       " 'to',\n",
       " 'the',\n",
       " 'stori',\n",
       " 'fail',\n",
       " 'by',\n",
       " 'make',\n",
       " 'the',\n",
       " 'director',\n",
       " 'cassi',\n",
       " 'relationship',\n",
       " 'so',\n",
       " 'promin',\n",
       " 'the',\n",
       " 'entir',\n",
       " 'ensembl',\n",
       " 'premis',\n",
       " 'of',\n",
       " 'the',\n",
       " 'music',\n",
       " 'sail',\n",
       " 'out',\n",
       " 'the',\n",
       " 'window',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'music',\n",
       " 'number',\n",
       " 'are',\n",
       " 'sped',\n",
       " 'up',\n",
       " 'and',\n",
       " 'rush',\n",
       " 'the',\n",
       " 'show',\n",
       " 's',\n",
       " 'hit',\n",
       " 'song',\n",
       " 'get',\n",
       " 'the',\n",
       " 'entir',\n",
       " 'mean',\n",
       " 'shatter',\n",
       " 'when',\n",
       " 'it',\n",
       " 'is',\n",
       " 'given',\n",
       " 'to',\n",
       " 'cassi',\n",
       " 's',\n",
       " 'charact',\n",
       " 'the',\n",
       " 'overal',\n",
       " 'stage',\n",
       " 'is',\n",
       " 'veri',\n",
       " 'self',\n",
       " 'consciou',\n",
       " 'the',\n",
       " 'onli',\n",
       " 'reason',\n",
       " 'i',\n",
       " 'give',\n",
       " 'it',\n",
       " 'a',\n",
       " '2',\n",
       " 'is',\n",
       " 'becaus',\n",
       " 'a',\n",
       " 'few',\n",
       " 'of',\n",
       " 'the',\n",
       " 'great',\n",
       " 'number',\n",
       " 'are',\n",
       " 'still',\n",
       " 'abl',\n",
       " 'to',\n",
       " 'be',\n",
       " 'enjoy',\n",
       " 'despit',\n",
       " 'the',\n",
       " 'film',\n",
       " 's',\n",
       " 'attempt',\n",
       " 'to',\n",
       " 'squeez',\n",
       " 'everi',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'joy',\n",
       " 'and',\n",
       " 'spontan',\n",
       " 'out',\n",
       " 'of',\n",
       " 'it']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_porter(df.loc[4,'review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7a34124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\himanshu\n",
      "[nltk_data]     pandey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7b22a02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recent',\n",
       " 'bought',\n",
       " 'dvd',\n",
       " 'forget',\n",
       " 'much',\n",
       " 'hate',\n",
       " 'movi',\n",
       " 'version',\n",
       " 'choru',\n",
       " 'line',\n",
       " 'everi',\n",
       " 'chang',\n",
       " 'director',\n",
       " 'attenborough',\n",
       " 'made',\n",
       " 'stori',\n",
       " 'fail',\n",
       " 'make',\n",
       " 'director',\n",
       " 'cassi',\n",
       " 'relationship',\n",
       " 'promin',\n",
       " 'entir',\n",
       " 'ensembl',\n",
       " 'premis',\n",
       " 'music',\n",
       " 'sail',\n",
       " 'window',\n",
       " 'music',\n",
       " 'number',\n",
       " 'sped',\n",
       " 'rush',\n",
       " 'show',\n",
       " 'hit',\n",
       " 'song',\n",
       " 'get',\n",
       " 'entir',\n",
       " 'mean',\n",
       " 'shatter',\n",
       " 'given',\n",
       " 'cassi',\n",
       " 'charact',\n",
       " 'overal',\n",
       " 'stage',\n",
       " 'veri',\n",
       " 'self',\n",
       " 'consciou',\n",
       " 'onli',\n",
       " 'reason',\n",
       " 'give',\n",
       " '2',\n",
       " 'becaus',\n",
       " 'great',\n",
       " 'number',\n",
       " 'still',\n",
       " 'abl',\n",
       " 'enjoy',\n",
       " 'despit',\n",
       " 'film',\n",
       " 'attempt',\n",
       " 'squeez',\n",
       " 'everi',\n",
       " 'bit',\n",
       " 'joy',\n",
       " 'spontan']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "[w for w in tokenizer_porter(df.loc[4,'review']) if w not in stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb5c45",
   "metadata": {},
   "source": [
    "##### Transform data to TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d89680c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer (strip_accents = None,\n",
    "                        lowercase = False,\n",
    "                        preprocessor = None,\n",
    "                        tokenizer = tokenizer_porter,\n",
    "                        use_idf=True,\n",
    "                        norm='l2',\n",
    "                        smooth_idf=True)\n",
    "y=df.sentiment.values\n",
    "x=tfidf.fit_transform(df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "690689ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c591a5",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3233f3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.3min remaining:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.4min finished\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "classifier=LogisticRegressionCV(cv=5,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs=-1,\n",
    "                       verbose=3,\n",
    "                       max_iter=300).fit(X_train,Y_train)\n",
    "saved_model = open('saved_model.sav','wb')\n",
    "pickle.dump(classifier,saved_model)\n",
    "saved_model.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5406f90",
   "metadata": {},
   "source": [
    "### MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bc30bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='saved_model.sav'\n",
    "saved_classifier=pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a636ebd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89696"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_classifier.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42a961",
   "metadata": {},
   "source": [
    "###### Accuracy of model comes out to be 89.6 percent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
